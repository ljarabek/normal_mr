{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2487/2487 [00:03<00:00, 640.59it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 193, 229, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1/15 [00:01<00:23,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ls 13126735.0 + Lc 108396.1171875  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:02<00:10,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ls 25629580.0 + Lc 120092.4375  \n",
      "2 Ls 2662351.5 + Lc 105558.765625  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:02<00:05,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Ls 8641408.0 + Lc 112149.3359375  \n",
      "4 Ls 10142208.0 + Lc 113679.3515625  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:02<00:02,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Ls 9322882.0 + Lc 113963.1015625  \n",
      "6 Ls 6405619.0 + Lc 110722.09375  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:02<00:01,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Ls 2581682.25 + Lc 106305.6953125  \n",
      "8 Ls 2219753.5 + Lc 104731.8125  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:02<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Ls 5543273.5 + Lc 106477.46875  \n",
      "10 Ls 3309422.75 + Lc 104769.9140625  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [00:03<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Ls 1472702.5 + Lc 102484.78125  \n",
      "12 Ls 1975980.875 + Lc 106769.375  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Ls 2845588.25 + Lc 105544.078125  \n",
      "14 Ls 3176953.0 + Lc 108486.8828125  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The checkpoint has been created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for d in range(20):\\n    try:\\n        #print(\"{} layer of decoder: {}\".format(8-d, np.array(act_decoder[8-d]).shape))\\n        print(\"{} layer of encoder: {}\".format(d, np.array(act_encoder[d]).shape))\\n    except:\\n        print(\"it\\'s broken bro\")\\n\\nfor d in range(20):\\n    try:\\n        #print(\"{} layer of decoder: {}\".format(8-d, np.array(act_decoder[8-d]).shape))\\n        print(\"{} layer of encoder: {}\".format(d, np.array(act_d_encoder[d]).shape))\\n    except:\\n        print(\"it\\'s broken bro\")\\n\\n        \\n        \\nfor d in range(20):\\n    try:\\n        print(\"{} layer of decoder: {}\".format(d, np.array(act_decoder[d]).shape))\\n        #print(\"{} layer of encoder: {}\".format(d, np.array(act_encoder[d]).shape))\\n    except:\\n        print(\"it\\'s broken bro\")'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from trainingUtils import save, load\n",
    "from layers import AdaIN\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "from preprocessing import DataStream\n",
    "import matplotlib.pyplot as plt\n",
    "from multi_slice_viewer import multi_slice_viewer\n",
    "from init_weights import encoder_weights, decoder_weights\n",
    "from tqdm import tqdm\n",
    "weights = sio.loadmat(\"weights.mat\")\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, sess, batch_size, root_dir=\"../healthy-axis2-slice100/\", ckpt=None):\n",
    "        \"\"\"\n",
    "        :param sess: tf.Session()\n",
    "        :param ckpt: str\n",
    "        :param batch_size: int\n",
    "        \"\"\"\n",
    "        self.data = DataStream(batch_size=batch_size, root_dir=root_dir)\n",
    "        self.sess = sess\n",
    "        self.ids, self.batch = self.data.get_batch()\n",
    "\n",
    "        self.weights_encoder = encoder_weights()\n",
    "\n",
    "        self.weights_decoder = decoder_weights()\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "        if ckpt:\n",
    "            self.saver.restore(self.sess, save_path=ckpt)\n",
    "            print(\"restored from checkpoint \" + str(ckpt))\n",
    "\n",
    "    def save(self, dir):\n",
    "        save(self.saver, self.sess, logdir=dir)\n",
    "    def encode(self, input):\n",
    "        \"\"\"\n",
    "        :param input: tf.Tensor (b h w c)\n",
    "        :return: activations of relu_1,2,3,4 ; output\n",
    "        \"\"\"\n",
    "        activations = []\n",
    "\n",
    "        with tf.name_scope('encoder'):  # TODO: UPORABLJAJO SD IN MEAN OD RELU1_1,2_1,3_1,4_1;; popravi L2 Losses...\n",
    "            #net = tf.pad(input, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            #activations.append(net)\n",
    "            net = tf.nn.conv2d(input, self.weights_encoder['conv2d_0'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_0b'][0, :])  # 3 channel input!\n",
    "            net = tf.nn.relu(net)\n",
    "            activations.append(net)\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_2'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_2b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            activations.append(net)\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_5'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_5b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            activations.append(net)\n",
    "            net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                                 padding='VALID', name=str(b'pool1', 'utf-8'))\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_9'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_9b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            activations.append(net) ## TODO: TUKAJ JE ZADNJA AKTIVACIJA ZA STYLE\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_12'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_12b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            #activations.append(net)\n",
    "            net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                                 padding='VALID', name=str(b'pool2', 'utf-8'))\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_16'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_16b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            #activations.append(net)\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_19'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_19b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            #activations.append(net)\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_22'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_22b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            #activations.append(net)\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_25'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_25b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            #activations.append(net)\n",
    "            net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                                 padding='VALID', name=str(b'pool3', 'utf-8'))\n",
    "            net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "            net = tf.nn.conv2d(net, self.weights_encoder['conv2d_29'], [1, 1, 1, 1], padding='VALID')\n",
    "            net = tf.nn.bias_add(net, self.weights_encoder['conv2d_29b'][0, :])\n",
    "            net = tf.nn.relu(net)\n",
    "            #activations.append(net)\n",
    "        return net, activations\n",
    "\n",
    "    def decode(self, input):\n",
    "        activations  = []\n",
    "        net = tf.pad(input, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_1'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_1b'][0, :])\n",
    "        net = tf.nn.relu(net)\n",
    "        activations.append(net)\n",
    "        d = tf.shape(net)\n",
    "        size = [d[1] * 2, d[2] * 2]\n",
    "        net = tf.image.resize_nearest_neighbor(net, size)\n",
    "        #!!! input v net spremen!!\n",
    "        net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_5'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_5b'][0, :])\n",
    "        net = tf.nn.relu(net)\n",
    "        activations.append(net)\n",
    "        net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_8'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_8b'][0, :])\n",
    "        net = tf.nn.relu(net)\n",
    "        activations.append(net)\n",
    "        net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_11'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_11b'][0, :])\n",
    "        net = tf.nn.relu(net)\n",
    "        activations.append(net)\n",
    "        net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_14'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_14b'][0, :])\n",
    "        net = tf.nn.relu(net)\n",
    "        activations.append(net)\n",
    "\n",
    "        d = tf.shape(net)\n",
    "        size = [d[1] * 2, d[2] * 2]\n",
    "        net = tf.image.resize_nearest_neighbor(net, size)\n",
    "\n",
    "        net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_18'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_18b'][0, :])\n",
    "        net = tf.nn.relu(net)\n",
    "        activations.append(net)\n",
    "        net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_21'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_21b'][0, :])\n",
    "        net = tf.nn.relu(net)\n",
    "        activations.append(net)\n",
    "\n",
    "        d = tf.shape(net)\n",
    "        size = [d[1] * 2, d[2] * 2]\n",
    "        net = tf.image.resize_nearest_neighbor(net, size)\n",
    "\n",
    "        net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_25'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_25b'][0, :])\n",
    "        net = tf.nn.relu(net)\n",
    "        activations.append(net)\n",
    "\n",
    "        net = tf.pad(net, [[0, 0], [1, 1], [1, 1], [0, 0]], 'REFLECT')\n",
    "        net = tf.nn.conv2d(net, self.weights_decoder['conv2d_28'], [1, 1, 1, 1], padding='VALID')\n",
    "        net = tf.nn.bias_add(net, self.weights_decoder['conv2d_28b'][0, :])\n",
    "        activations.append(net)\n",
    "        return activations, net\n",
    "\n",
    "    def build_model(self):\n",
    "        self.lr = tf.Variable(0.003, False, name='learning_rate')\n",
    "\n",
    "        self.input_c = tf.Variable(np.float32(self.batch), trainable=False, name='input_content')\n",
    "        self.input_s = tf.Variable(np.float32(self.batch), trainable=False, name='input_style')\n",
    "        \n",
    "        \n",
    "        inp_c = self.input_c[:,0:192, 0:224]  # 192, 224, 1\n",
    "        inp_s = self.input_s[:,0:192, 0:224]\n",
    "        self.latent_c, self.act_c = self.encode(input=inp_c)\n",
    "\n",
    "        self.latent_s, self.act_s = self.encode(input=inp_s)\n",
    "\n",
    "        self.latent_c_s = AdaIN(self.latent_c, self.latent_s, 1.0)\n",
    "\n",
    "        self.act_d, self.output = self.decode(input=self.latent_c_s)\n",
    "\n",
    "        self.output_recon_c, self.act_r_c = self.encode(input=self.output)\n",
    "\n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss_content = tf.reduce_mean(\n",
    "                tf.square(self.output_recon_c - self.latent_c_s))  # prej je blo reduce mean - tf.square (MSE)\n",
    "            m_std_loss = []\n",
    "            for orig_s, recon_s in zip(self.act_s, self.act_r_c):\n",
    "                s_mean, s_var = tf.nn.moments(orig_s, [1, 2])\n",
    "                r_mean, r_var = tf.nn.moments(recon_s, [1, 2])\n",
    "\n",
    "                mean_l = tf.reduce_mean(tf.square(s_mean - r_mean))  # prej je blo reduce sum - tf.square\n",
    "                std_l = tf.reduce_mean(tf.square(tf.sqrt(s_var) - tf.sqrt(r_var)))\n",
    "\n",
    "                m_std_loss.append([mean_l, std_l])\n",
    "            self.loss_style = tf.reduce_mean(m_std_loss)  # 5e-8 *\n",
    "\n",
    "            self.loss = self.loss_content + self.loss_style *0.3#* 0.03  # + self.loss_content  # +self.loss_style)#self.loss_style #self.loss_content 0.001*  #\n",
    "\n",
    "        self.minimizeLoss = tf.train.AdamOptimizer(learning_rate=0.0003).minimize(self.loss)  # 0.0000003\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "    #def train_step(self, same_style = True):\n",
    "    #    idsc, batchc = self.data.get_batch()\n",
    "    #    batchs = self.data.get_fixed_batch()\n",
    "    #    self.sess.run(self.minimizeLoss, feed_dict={})\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    mod = Model(sess=sess, batch_size=5)\n",
    "    # lr = tf.Variable(0.003, False, name='learning_rate')\n",
    "    # tf.global_variables_initializer().run()\n",
    "    idss, batchs = mod.data.get_fixed_batch()\n",
    "    for i in tqdm(range(15)):\n",
    "        idsc, batchc = mod.data.get_batch()\n",
    "        if idsc == idss:\n",
    "            continue\n",
    "        output, rc, _, ls, lc, act_decoder, act_encoder, act_d_encoder = sess.run(\n",
    "            (mod.output, mod.output_recon_c, mod.minimizeLoss, mod.loss_style, \n",
    "             mod.loss_content, mod.act_d, mod.act_s, mod.act_r_c),\n",
    "            feed_dict={mod.input_c: batchc, mod.input_s: batchs})\n",
    "\n",
    "        #if (i == 1):\n",
    "        #    plt.imshow(batchs[0, :, :, 0])\n",
    "        #    plt.show()\n",
    "        #    plt.imshow(output[0, :, :, 0])\n",
    "        #    plt.show()\n",
    "        print(str(i) + \" Ls {} + Lc {}  \".format(ls, lc))  # str(i) + str(idss) + str(idsc) +\n",
    "        # print(tf.trainable_variables())\n",
    "    mod.save(\"../checkpoints/ckpts4/\")\n",
    "\n",
    "    # print(np.array(mod.numbers).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
